"""
IMAGE RECEIVING:  This python Kafka client receives images from outside Apache Kafka,
                  stores these images in object storage, saves their metadata in a
                  relational database, copies the images to the image analysis directory
                  for future analysis by the Kafka image analysis client, and sends a
                  Kafka message about it to that client.

                  NOTE: with the application being a MOCK image pipeline, the received
                  images are generated by this client from a first original image.
"""

from constants.CONSTANTS import *

import os
import shutil

# Pillow for image handling
from PIL import Image

# Apache Kafka    
from kafka import KafkaProducer
import json

# Amazon RDS MySQL database
import mysql.connector
from mysql.connector import Error

# Amazon S3 object storage
import boto3
from datetime import datetime
import logging
from botocore.exceptions import ClientError

# =====================================================================

# RDS endpoint and database credentials
DB_HOST     = "image-pipeline.cja6aao2uw8s.us-west-2.rds.amazonaws.com"
DB_NAME     = "image_pipeline"
DB_USER     = "admin"
DB_PASSWORD = "nancygraceroman"

# Amazon S3 bucket name
BUCKET_NAME = 'ngr-image-pipeline-bucket'

# --------------------------------------------------------------------------------

def generate_image(image_num, image_filename):
    """
    For the MOCK image pipeline, the image to be received is generated here from
    an original image (image # = 1) or from a previously generated image (image # > 1)
    """

    image_recv_path = IMAGE_RECV_DIR + "/" + image_filename

    prev_image_num = image_num - 1

    # Use an original image to be the first received image
    if image_num == 1:
        prev_image_recv_path = ""
        shutil.copy(ORIGINAL_IMAGE_PATH, image_recv_path)

    # generate an image from the previously received image
    else:
        prev_image_recv_path = IMAGE_RECV_DIR + "/" + f"image_{prev_image_num:05d}.jpg"

        # every so often, modify the previous image to generate a new changed image
        if image_num % 4 == 3:
            print("... CHANGING IMAGE: Rotating 90Â°")
            prev_image = Image.open(prev_image_recv_path)
            rotated_image = prev_image.rotate(90)
            rotated_image.save(image_recv_path)
            rotated_image.close()
            prev_image.close()

        # copy the previous image w/o modification to generate the new image
        else:
            shutil.copy(prev_image_recv_path, image_recv_path)

    return image_recv_path, prev_image_recv_path

# ------------------------------------------------------------------------

def store_image(image_filename, image_recv_path):

    """
    Stores the image itself in object storage. Returns image storage key.
    """

    logging.basicConfig(level=logging.INFO)

    # Boto3 automatically uses the IAM role attached to the EC2 instance
    s3_client  = boto3.client('s3')

    image_key      = f'image/{image_filename}'

    try:
        s3_client.upload_file(image_recv_path, BUCKET_NAME, image_key)
        logging.info(f"'{image_filename}' successfully uploaded to '{BUCKET_NAME}/{image_key}'")

    except ClientError as e:
        logging.error(f"Failed to access S3: {e}")
    except Exception as e:
        logging.error(f"An unexpected error occurred: {e}")
        return False
    finally:
        s3_client.close()
        return image_key

# ------------------------------------------------------------------------

def save_image(image_filename, image_recv_path):

    """
    Saves image metadata in relational database and the image itself in
    object database. Returns database table automatically generated
    image_id number.
    """

    # store image itself in object database
    image_key = store_image(image_filename, image_recv_path)

    # this will contain the primary key's automatically generated
    # integer value from adding the image's metadata to the image 
    # database table
    image_id = -1

    try:
        connection = mysql.connector.connect(
            host     = DB_HOST,
            database = DB_NAME,
            user     = DB_USER,
            password = DB_PASSWORD
        )

        if connection.is_connected():

            db_info = connection.server_info
            print(f"Connected to MySQL Server version {db_info}")

            cursor = connection.cursor()

            # Add image's metadata to the image database table
            print(f"Adding image filename {image_filename} and its image key {image_key} to the image database table")
            add_image_query = f"INSERT INTO image (filename, image_key) VALUES ('{image_filename}', '{image_key}')"
            print(add_image_query)
            cursor.execute(add_image_query)
            connection.commit()

            # this is the integer just automatically generated for the new row's image_id
            # column in the image table
            image_id = cursor.lastrowid

    except Error as e:
        print(f"Error connecting to MySQL database: {e}")

    finally:
        if connection is not None and connection.is_connected():
            cursor.close()
            connection.close()
            print("MySQL connection is closed.")

    return image_id

# -----------------------------------------------------------------------------------

def receive_image(image_num, image_filename, image_recv_path, prev_image_recv_path):

    """
    Receives the next image, storing its metadata in a relational database,
    storing the image itself in object storage, and putting a copy of it in
    the image analysis directory so that the Kafka image analysis client
    an analyze it.
    """

    # a copy of the image will be saved here for analysis by the Kafka image analysis client
    image_analysis_path = IMAGE_ANALYSIS_DIR + "/" + image_filename

    # store image metadata in relational database and image in object storage;
    # returned image_id will be passed to the Kafka image analysis client
    image_id = save_image(image_filename, image_recv_path)

    # copy received image to the image analysis directory
    # so that the Kafka image analysis client can analyze it
    # using the previously received image that was already
    # copied there in the previous iteration
    shutil.copy(image_recv_path, image_analysis_path)

    # if not on first received image in the image stream, remove the
    # previously received image from the image receiving directory
    # because don't need it anymore for generating the next image
    if image_num != 1:
        os.remove(prev_image_recv_path)

    # if just received the last image in the image stream, don't need
    # to keep it around in the image receiving directory to use as a
    # a previous image to generate the next image
    if image_num == TOTAL_NUM_IMAGES:
        os.remove(image_recv_path)

    return image_id, image_analysis_path

# ===================================================================================

if __name__ == "__main__":

    # Create a Kafka Producer instance for image receiving
    producer = KafkaProducer(
        bootstrap_servers=['localhost:9092'],
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )

    print()
    print("Starting image receiving Apache Kafka client ...")
    print("CODE_DIR = ",CODE_DIR)
    print()

    image_num  =  1
    while image_num <= TOTAL_NUM_IMAGES:

        image_filename = f"image_{image_num:05d}.jpg"    

        # Since this a mock image pipeline, need to generate the next image to be received
        print("Generating Image # = ", image_num)
        image_recv_path, prev_image_recv_path = generate_image(image_num, image_filename)

        print("Receiving Image  # = ", image_num)
        image_id, image_analysis_path = receive_image(image_num, image_filename, image_recv_path, prev_image_recv_path)

        # Send a Kafka message to the image analysis client
        message_data = {'image_num': image_num, 'image_id': image_id, 'image_filename': image_filename,
                        'image_analysis_path': image_analysis_path}
        producer.send(IMAGE_ANALYSIS_TOPIC, message_data)
        # Flush message to ensure delivery
        producer.flush()
        print(f"Message sent to topic '{IMAGE_ANALYSIS_TOPIC}': {message_data}")
        print()

        image_num += 1

