"""
IMAGE RECEIVING:  "receives" the image from outside Apache Kafka, "stores" it in the
(Kafka client)    image "database," copies the image to the image analysis directory
                  for future analysis by the image analysis Kafka client
                  and sends a Kafka message about it to the image analysis client.

                  NOTE: with the whole application being a MOCK image pipeline, the
                  received images are generated by this client from a first original
                  image and the image "database" is actually a directory of image files.
"""

from constants.CONSTANTS import *

import os
import shutil

# Pillow for image handling
from PIL import Image

# Apache Kafka    
from kafka import KafkaProducer
import json

# Amazon RDS MySQL database
import mysql.connector
from mysql.connector import Error

# Amazon S3 object storage
import boto3
from datetime import datetime
import logging
from botocore.exceptions import ClientError

# --------------------------------------------------------------------------------

def generate_image(image_num):
    """
    For the MOCK image pipeline, the image to be received is generated here from
    an original image (image # = 1) or from a previously generated image (image # > 1)
    """

    prev_image_num = image_num - 1

    # Use an original image to generate first image to be received
    if image_num == 1:
        prev_image_recv_path      = ""
        image_recv_path           = IMAGE_RECV_DIR + "/00001.jpg"
        shutil.copy(ORIGINAL_IMAGE_PATH,image_recv_path)

    # generate an image from the previously received image
    else:
        prev_image_recv_path = IMAGE_RECV_DIR + "/" + f"{prev_image_num:05d}" + ".jpg"
        image_recv_path      = IMAGE_RECV_DIR + "/" + f"{image_num:05d}"      + ".jpg"

        # every so often, modify the previous image to generate a different image
        if image_num % 4 == 3:
            print("... CHANGING IMAGE: Rotating 90Â°")
            prev_image = Image.open(prev_image_recv_path)
            rotated_image = prev_image.rotate(90)
            rotated_image.save(image_recv_path)
            rotated_image.close()
            prev_image.close()

        # copy the previous image w/o modification to generate the new image
        else:
            shutil.copy(prev_image_recv_path,image_recv_path)

    return image_recv_path, prev_image_recv_path

# ------------------------------------------------------------------------

def store_image(image_recv_path):

    logging.basicConfig(level=logging.INFO)

    # Boto3 automatically uses the IAM role attached to the EC2 instance
    s3_client  = boto3.client('s3')

    filename   = os.path.basename(image_recv_path)
    bucket     = 'ngr-image-pipeline-bucket' # Replace with your S3 bucket name
    image_key = f'image/{filename}'

    try:
        s3_client.upload_file(image_recv_path, bucket, image_key)
        logging.info(f"'{filename}' successfully uploaded to '{bucket}/{image_key}'")

    except ClientError as e:
        logging.error(f"Failed to access S3: {e}")
    except Exception as e:
        logging.error(f"An unexpected error occurred: {e}")
        return False
    finally:
        s3_client.close()
        return image_key

# ------------------------------------------------------------------------

def save_image(image_recv_path):

    filename = os.path.basename(image_recv_path)

    # RDS endpoint and database credentials
    DB_HOST     = "image-pipeline.cja6aao2uw8s.us-west-2.rds.amazonaws.com"
    DB_NAME     = "image_pipeline"
    DB_USER     = "admin"
    DB_PASSWORD = "nancygraceroman"

    image_key = store_image(image_recv_path)

    try:
        connection = mysql.connector.connect(
            host     = DB_HOST,
            database = DB_NAME,
            user     = DB_USER,
            password = DB_PASSWORD
        )

        if connection.is_connected():

            db_info = connection.server_info
            print(f"Connected to MySQL Server version {db_info}")

            cursor = connection.cursor()

            print(f"Adding image filename {filename} and it's image key {image_key} to the image database table")

            add_image = f"INSERT INTO image (filename, image_key) VALUES ('{filename}', '{image_key}')"
            print(add_image)
            cursor.execute(add_image)

            connection.commit()

    except Error as e:
        print(f"Error connecting to MySQL database: {e}")

    finally:
        if connection is not None and connection.is_connected():
            cursor.close()
            connection.close()
            print("MySQL connection is closed.")

# -----------------------------------------------------------------------------------

def receive_image(image_num, image_recv_path, prev_image_recv_path):
    """
    Receives the next image, storing it in the image "database" and
    putting a copy of it in the image analysis directory so that the
    image analysis client can analyze it.
    """

    image_db_path       = IMAGE_DB_DIR       + "/" + f"{image_num:05d}" + ".jpg"
    image_analysis_path = IMAGE_ANALYSIS_DIR + "/" + f"{image_num:05d}" + ".jpg"

    # store image metadata in database and image in object storage
    save_image(image_recv_path)

    # copy received image to the image analysis directory
    # so that the image analysis client can analyze it
    shutil.copy(image_recv_path, image_analysis_path)

    # if not on first received image, remove the previous image because
    # don't need it anymore for generating the next image
    if image_num != 1:
        os.remove(prev_image_recv_path)

    # if just received the last image, don't need to keep it around as a 
    # previous image to generate the next image
    if image_num == TOTAL_NUM_IMAGES:
        os.remove(image_recv_path)

# ===================================================================================

if __name__ == "__main__":

    """
    # Create a Kafka Producer instance
    producer = KafkaProducer(
        bootstrap_servers=['localhost:9092'],
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )
    """

    print()
    print("Starting image receiving Apache Kafka client ...")
    print("CODE_DIR = ",CODE_DIR)
    print()

    image_num  =  1
    while image_num <= TOTAL_NUM_IMAGES:

        # Since this a mock image pipeline, need to generate the images to be received
        print("Generating Image # = ", image_num)
        image_recv_path, prev_image_recv_path = generate_image(image_num)

        print("Receiving Image  # = ", image_num)
        receive_image(image_num, image_recv_path, prev_image_recv_path)

        """
        # Send a Kafka message to the image analysis client
        message_data = {'image_num': image_num}
        producer.send(IMAGE_ANALYSIS_TOPIC, message_data)
        # Flush message to ensure delivery
        producer.flush()

        print(f"Message sent to topic '{IMAGE_ANALYSIS_TOPIC}': {message_data}")
        print()
        """

        image_num += 1

